![Ironhack logo](https://i.imgur.com/1QgrNNw.png)

# Lab | Introduction to Apache Spark

## Introduction

This lab will introduce you to one of the most popular and cutting-edge computing frameworks - [Apache Spark](https://spark.apache.org/). Spark is a fast, in-memory data processing engine with developer-friendly APIs that allows data engineers to deploy and execute big data applications with ease and efficiency. **If you are motivated to continue developing yourself on the data engineering track, Spark is an extremely useful technology to learn.**

Please be advised that in addition to a good foundation in Python and in technology in general, you are also recommended to have a mid- to high-profile computer for this lab because you will be executing millions of repeated sampling queries that run in parallel queues. Therefore, your computer should have multi-core CPUs and adequate memory. Refer to Technical Requirements below for details. Although a powerful computer is not required (as you can skip executing the repeated sampling code), it is strongly recommended so that you will get the most of this lab.

### Objectives

* Understanding the concepts, architecture, and application of Apache Spark.
* Install PySpark with Jupyter Notebook integration in local mode.
* Complete a data analysis demo with PySpark.
* [OPTIONAL] Deploy PySpark cluster mode with Databricks.
* Brainstorm how you want to use Apache Spark in your final project.

### Technical Requirements

* Processor - Intel i5 quad-core or above
* Memory - 4gb or above
* OS 
	* macOS: High Sierra or above
	* Windows 8 or above
* Software required/to be installed
	* Latest homebrew
	* Pip
	* Java SDK
	* Apache Spark (PySpark)
	* Xcode (macOS)
	* Anaconda (Windows)

## Getting Started

Complete Challenge 1-4 in order. Try to finish at least Challenge 1 and 2 in the morning so that you'll have enough time to work on Challenge 3 and 4 in the afternoon. Challenge 4 is not required but it will be useful if you want to use Apache Spark in your final project.

## Deliverables

- `challenge-3.ipynb`.
- Published Databricks Jupyter Notebook.

## Submission

* Submit `challenge-3.ipynb` with your solutions via git.
* Submit the link to your published Notebook in a text file.
